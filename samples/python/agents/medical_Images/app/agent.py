import base64
import os
from collections.abc import AsyncIterable
from pathlib import Path
from typing import Any, Literal

from langchain.memory import ConversationSummaryBufferMemory
from langchain_community.tools import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel


class MedicalResponseFormat(BaseModel):
    """Formato de respuesta m√©dica estructurada."""
    
    status: Literal['analyzing_images', 'classifying', 'searching', 'generating_response', 'input_required', 'completed', 'error'] = 'analyzing_images'
    message: str
    section: Literal['visual_findings', 'classification', 'search_results', 'final_response', 'general'] = 'general'


class MedicalAgent:
    """Agente m√©dico con an√°lisis de im√°genes, b√∫squeda y memoria conversacional."""
    
    SYSTEM_INSTRUCTION = (
        'Eres un m√©dico especialista experimentado que analiza consultas m√©dicas, '
        'im√°genes m√©dicas y proporciona an√°lisis profesionales. '
        'Debes ser claro, objetivo y siempre incluir disclaimers apropiados. '
        'NUNCA proporciones diagn√≥sticos definitivos. '
        'Siempre menciona que tu an√°lisis no sustituye una consulta m√©dica presencial.'
    )
    
    SUPPORTED_CONTENT_TYPES = ['text', 'text/plain', 'image/jpeg', 'image/png', 'image/webp']
    
    def __init__(self):
        """Inicializar el agente m√©dico."""
        # Modelo principal
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.3,
            max_output_tokens=4096,
        )
        
        # Herramienta de b√∫squeda
        self.tavily_tool = TavilySearchResults(
            max_results=3,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=False,
            include_images=False
        )
        
        # Memoria conversacional por contexto
        self.memories = {}
        
        # Almacenamiento temporal de hallazgos visuales por contexto
        self.visual_findings = {}
    
    def _get_or_create_memory(self, context_id: str):
        """Obtener o crear memoria para un contexto espec√≠fico."""
        if context_id not in self.memories:
            self.memories[context_id] = ConversationSummaryBufferMemory(
                llm=self.llm,
                max_token_limit=2000,
                return_messages=True
            )
        return self.memories[context_id]
    
    def _get_memory_context(self, context_id: str) -> str:
        """Obtener el contexto de memoria para un contexto espec√≠fico."""
        memory = self._get_or_create_memory(context_id)
        try:
            memory_variables = memory.load_memory_variables({})
            history_messages = memory_variables.get("history", [])
            if history_messages:
                return "\n".join([
                    f"{type(msg).__name__}: {msg.content}" 
                    for msg in history_messages
                ])
            return "Primera consulta del paciente."
        except Exception:
            return "Primera consulta del paciente."
    
    def _save_to_memory(self, context_id: str, query: str, response: str):
        """Guardar interacci√≥n en memoria."""
        memory = self._get_or_create_memory(context_id)
        memory.save_context({"input": query}, {"output": response})
    
    def encode_image(self, image_data: bytes) -> str:
        """Codifica imagen en base64."""
        return base64.b64encode(image_data).decode('utf-8')
    
    def decode_base64_image(self, base64_string: str) -> bytes:
        """Decodifica una imagen desde base64."""
        return base64.b64decode(base64_string)
    
    def get_mime_type(self, content_type: str) -> str:
        """Mapea content_type a MIME type para Gemini."""
        mapping = {
            'image/jpeg': 'image/jpeg',
            'image/png': 'image/png',
            'image/webp': 'image/webp',
            'image/gif': 'image/gif',
        }
        return mapping.get(content_type, 'image/png')
    
    async def analyze_images(self, images: list[dict]) -> str:
        """
        Analiza im√°genes m√©dicas con Gemini Vision.
        
        Args:
            images: Lista de diccionarios con:
                - 'data' (bytes o str base64)
                - 'mime_type' (str)
        
        Returns:
            Hallazgos visuales como string
        """
        if not images:
            return "No se proporcionaron im√°genes para an√°lisis."
        
        # Preparar contenido del mensaje
        content = [{
            "type": "text",
            "text": f"""Analiza estas {len(images)} im√°genes m√©dicas y proporciona una lista de HALLAZGOS CLAVES.

Formato de salida:
HALLAZGO 1: [Descripci√≥n espec√≠fica del hallazgo]
HALLAZGO 2: [Descripci√≥n espec√≠fica del hallazgo]
...

Enf√≥cate en:
- Anomal√≠as visibles
- Caracter√≠sticas anat√≥micas relevantes
- Patrones de inter√©s cl√≠nico
- Comparaciones con normalidad esperada

S√© espec√≠fico y objetivo. Evita diagn√≥sticos definitivos."""
        }]
        
        # Agregar im√°genes
        for idx, img in enumerate(images):
            try:
                # Manejar tanto bytes como base64 string
                image_data_raw = img.get('data') or img.get('bytes')
                
                if isinstance(image_data_raw, bytes):
                    # Ya son bytes, codificar directamente
                    image_data_b64 = self.encode_image(image_data_raw)
                elif isinstance(image_data_raw, str):
                    # Ya es base64, usar directamente
                    image_data_b64 = image_data_raw
                else:
                    print(f"‚ö†Ô∏è Tipo de dato no soportado para imagen {idx}: {type(image_data_raw)}")
                    continue
                
                mime_type = self.get_mime_type(img.get('mime_type', 'image/png'))
                
                # Agregar imagen al contenido
                content.append({
                    "type": "image_url",
                    "image_url": f"data:{mime_type};base64,{image_data_b64}"
                })
                
                print(f"‚úÖ Imagen {idx} agregada: {mime_type}, tama√±o base64: {len(image_data_b64)}")
                
            except Exception as e:
                print(f"‚ùå Error procesando imagen {idx}: {e}")
                continue
        
        # Verificar que se agregaron im√°genes
        image_count = len([c for c in content if c.get('type') == 'image_url'])
        if image_count == 0:
            return "Error: No se pudieron procesar las im√°genes proporcionadas."
        
        print(f"üì§ Enviando {image_count} imagen(es) a Gemini para an√°lisis...")
        
        message = HumanMessage(content=content)
        
        try:
            response = self.llm.invoke([message])
            print(f"‚úÖ An√°lisis de im√°genes completado")
            return response.content
        except Exception as e:
            error_msg = f"Error en an√°lisis de im√°genes: {str(e)}"
            print(f"‚ùå {error_msg}")
            return error_msg
    
    async def classify_query(self, query: str, context: str, visual_findings: str) -> str:
        """Clasifica la consulta m√©dica."""
        system_prompt = """Eres un m√©dico especialista que analiza consultas m√©dicas.
Tu tarea es identificar:
1. El tipo de consulta (diagn√≥stico, seguimiento, segunda opini√≥n, etc.)
2. Los hallazgos visuales mencionados o relevantes
3. Las palabras clave m√©dicas importantes

Formato de respuesta:
TIPO_CONSULTA: [tipo]
HALLAZGOS_RELEVANTES: [lista]
KEYWORDS_MEDICAS: [palabras clave]
ESPECIALIDAD_SUGERIDA: [especialidad m√©dica relevante]"""
        
        user_prompt = f"""
HALLAZGOS VISUALES IDENTIFICADOS:
{visual_findings}

CONTEXTO DE CONVERSACI√ìN PREVIA:
{context}

CONSULTA DEL PACIENTE/USUARIO:
{query}

Clasifica esta consulta m√©dica seg√∫n los hallazgos y el contexto proporcionado."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error en clasificaci√≥n: {str(e)}"
    
    async def generate_search_queries(self, classification: str, visual_findings: str, 
                                     original_query: str) -> str:
        """Genera consultas de b√∫squeda optimizadas."""
        system_prompt = """Eres un experto en b√∫squeda de informaci√≥n m√©dica.
Genera consultas de b√∫squeda m√©dicas precisas y profesionales.

Reglas:
- Usa terminolog√≠a m√©dica precisa
- Enf√≥cate en informaci√≥n cl√≠nica relevante
- Prioriza fuentes m√©dicas confiables

Responde SOLO con la consulta de b√∫squeda optimizada, sin explicaciones."""
        
        user_prompt = f"""
CLASIFICACI√ìN M√âDICA:
{classification}

HALLAZGOS VISUALES:
{visual_findings}

CONSULTA ORIGINAL:
{original_query}

Genera la mejor consulta de b√∫squeda m√©dica para esta informaci√≥n."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error generando consultas: {str(e)}"
    
    async def search_medical_info(self, search_query: str) -> str:
        """Busca informaci√≥n m√©dica en Tavily."""
        try:
            result = self.tavily_tool.invoke({"query": search_query})
            
            if isinstance(result, list) and len(result) > 0:
                content = result[0].get('answer', result[0].get('content', ''))
                return f"B√∫squeda: {search_query}\n{content}"
            else:
                return f"B√∫squeda: {search_query}\nNo se encontr√≥ informaci√≥n espec√≠fica."
        except Exception as e:
            return f"Error en b√∫squeda: {str(e)}"
    
    async def generate_medical_response(self, query: str, context: str, 
                                       classification: str, visual_findings: str,
                                       search_info: str) -> str:
        """Genera la respuesta m√©dica final."""
        system_prompt = """Eres un m√©dico especialista experimentado que proporciona an√°lisis m√©dicos claros y profesionales.

**Estructura tu respuesta en estas secciones:**
1. DESCRIPCI√ìN GENERAL: Resumen breve de la consulta
2. HALLAZGOS PRINCIPALES: Basado en los hallazgos visuales identificados
3. INTERPRETACI√ìN CL√çNICA: Integra la informaci√≥n de b√∫squeda m√©dica
4. CONSIDERACIONES DIAGN√ìSTICAS: Posibles diagn√≥sticos diferenciales
5. RECOMENDACIONES: Pasos siguientes sugeridos

**Reglas importantes:**
- Usa lenguaje m√©dico profesional pero accesible
- Siempre incluye disclaimers apropiados (no sustituye consulta m√©dica presencial)
- Basa tus conclusiones en evidencia
- S√© claro sobre las limitaciones del an√°lisis remoto
- Nunca proporciones diagn√≥sticos definitivos"""
        
        user_prompt = f"""
**CONSULTA ORIGINAL DEL USUARIO:**
{query}

**CONTEXTO DE CONVERSACI√ìN ANTERIOR:**
{context}

**CLASIFICACI√ìN M√âDICA:**
{classification}

**HALLAZGOS VISUALES DE LAS IM√ÅGENES:**
{visual_findings}

**INFORMACI√ìN M√âDICA DE B√öSQUEDA:**
{search_info}

Proporciona un an√°lisis m√©dico completo y profesional."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error generando respuesta: {str(e)}"
    
    async def stream(self, query: str, context_id: str, 
                    images: list[dict] = None) -> AsyncIterable[dict[str, Any]]:
        """
        Procesa una consulta m√©dica con streaming.
        
        Args:
            query: Consulta del usuario
            context_id: ID del contexto de conversaci√≥n
            images: Lista opcional de im√°genes [{'data': bytes o str, 'mime_type': str}]
        
        Yields:
            Diccionarios con informaci√≥n de progreso y respuestas
        """
        print(f"\n{'='*80}")
        print(f"üè• Procesando consulta m√©dica")
        print(f"Context ID: {context_id}")
        print(f"Query: {query[:100]}...")
        print(f"Im√°genes recibidas: {len(images) if images else 0}")
        print(f"{'='*80}\n")
        
        # Obtener contexto de memoria
        memory_context = self._get_memory_context(context_id)
        
        # PASO 1: Analizar im√°genes si existen
        visual_findings = ""
        if images and len(images) > 0:
            print(f"üì∏ Analizando {len(images)} imagen(es)...")
            
            yield {
                'is_task_complete': False,
                'require_user_input': False,
                'content': f'Analizando {len(images)} imagen(es) m√©dica(s)...',
                'status': 'analyzing_images'
            }
            
            visual_findings = await self.analyze_images(images)
            self.visual_findings[context_id] = visual_findings
            
            print(f"‚úÖ An√°lisis visual completado")
            print(f"Hallazgos: {visual_findings[:200]}...")
            
            yield {
                'is_task_complete': False,
                'require_user_input': False,
                'content': f'Hallazgos visuales identificados.',
                'status': 'analyzing_images'
            }
        else:
            # Usar hallazgos previos si existen
            visual_findings = self.visual_findings.get(
                context_id, 
                "No se proporcionaron im√°genes para an√°lisis."
            )
            print(f"‚ÑπÔ∏è No hay im√°genes nuevas, usando hallazgos previos")
        
        # PASO 2: Clasificar consulta
        print(f"üîç Clasificando consulta...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'Clasificando consulta m√©dica...',
            'status': 'classifying'
        }
        
        classification = await self.classify_query(query, memory_context, visual_findings)
        print(f"‚úÖ Clasificaci√≥n completada")
        
        # PASO 3: Generar consultas de b√∫squeda
        print(f"üîé Generando consultas de b√∫squeda...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'Buscando informaci√≥n m√©dica relevante...',
            'status': 'searching'
        }
        
        search_query = await self.generate_search_queries(
            classification, visual_findings, query
        )
        print(f"‚úÖ Query de b√∫squeda: {search_query[:100]}...")
        
        # PASO 4: Buscar informaci√≥n
        print(f"üåê Buscando informaci√≥n m√©dica...")
        search_info = await self.search_medical_info(search_query)
        print(f"‚úÖ B√∫squeda completada")
        
        # PASO 5: Generar respuesta final
        print(f"üìù Generando respuesta m√©dica final...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'Generando an√°lisis m√©dico completo...',
            'status': 'generating_response'
        }
        
        final_response = await self.generate_medical_response(
            query, memory_context, classification, visual_findings, search_info
        )
        
        print(f"‚úÖ Respuesta generada: {len(final_response)} caracteres")
        
        # Guardar en memoria
        self._save_to_memory(context_id, query, final_response)
        
        print(f"‚úÖ Consulta m√©dica completada\n")
        
        # Retornar respuesta final
        yield {
            'is_task_complete': True,
            'require_user_input': False,
            'content': final_response,
            'status': 'completed'
        }
