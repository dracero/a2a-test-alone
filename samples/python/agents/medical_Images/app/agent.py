import base64
import os
from collections.abc import AsyncIterable
from pathlib import Path
from typing import Any, Literal

from langchain.memory import ConversationSummaryBufferMemory
from langchain_community.tools import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel


class MedicalResponseFormat(BaseModel):
    """Formato de respuesta mÃ©dica estructurada."""
    
    status: Literal['analyzing_images', 'classifying', 'searching', 'generating_response', 'input_required', 'completed', 'error'] = 'analyzing_images'
    message: str
    section: Literal['visual_findings', 'classification', 'search_results', 'final_response', 'general'] = 'general'


class MedicalAgent:
    """Agente mÃ©dico con anÃ¡lisis de imÃ¡genes, bÃºsqueda y memoria conversacional."""
    
    SYSTEM_INSTRUCTION = (
        'Eres un mÃ©dico especialista experimentado que analiza consultas mÃ©dicas, '
        'imÃ¡genes mÃ©dicas y proporciona anÃ¡lisis profesionales. '
        'Debes ser claro, objetivo y siempre incluir disclaimers apropiados. '
        'NUNCA proporciones diagnÃ³sticos definitivos. '
        'Siempre menciona que tu anÃ¡lisis no sustituye una consulta mÃ©dica presencial.'
    )
    
    SUPPORTED_CONTENT_TYPES = ['text', 'text/plain', 'image/jpeg', 'image/png', 'image/webp']
    
    def __init__(self):
        """Inicializar el agente mÃ©dico."""
        # Modelo principal
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.3,
            max_output_tokens=4096,
        )
        
        # Herramienta de bÃºsqueda
        self.tavily_tool = TavilySearchResults(
            max_results=3,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=False,
            include_images=False
        )
        
        # Memoria conversacional por contexto
        self.memories = {}
        
        # Almacenamiento temporal de hallazgos visuales por contexto
        self.visual_findings = {}
    
    def _get_or_create_memory(self, context_id: str):
        """Obtener o crear memoria para un contexto especÃ­fico."""
        if context_id not in self.memories:
            self.memories[context_id] = ConversationSummaryBufferMemory(
                llm=self.llm,
                max_token_limit=2000,
                return_messages=True
            )
        return self.memories[context_id]
    
    def _get_memory_context(self, context_id: str) -> str:
        """Obtener el contexto de memoria para un contexto especÃ­fico."""
        memory = self._get_or_create_memory(context_id)
        try:
            memory_variables = memory.load_memory_variables({})
            history_messages = memory_variables.get("history", [])
            if history_messages:
                return "\n".join([
                    f"{type(msg).__name__}: {msg.content}" 
                    for msg in history_messages
                ])
            return "Primera consulta del paciente."
        except Exception:
            return "Primera consulta del paciente."
    
    def _save_to_memory(self, context_id: str, query: str, response: str):
        """Guardar interacciÃ³n en memoria."""
        memory = self._get_or_create_memory(context_id)
        memory.save_context({"input": query}, {"output": response})
    
    def encode_image(self, image_data: bytes) -> str:
        """Codifica imagen en base64."""
        return base64.b64encode(image_data).decode('utf-8')
    
    def decode_base64_image(self, base64_string: str) -> bytes:
        """Decodifica una imagen desde base64."""
        return base64.b64decode(base64_string)
    
    def get_mime_type(self, content_type: str) -> str:
        """Mapea content_type a MIME type para Gemini."""
        mapping = {
            'image/jpeg': 'image/jpeg',
            'image/png': 'image/png',
            'image/webp': 'image/webp',
            'image/gif': 'image/gif',
        }
        return mapping.get(content_type, 'image/png')
    
    async def analyze_images(self, images: list[dict]) -> str:
        """
        Analiza imÃ¡genes mÃ©dicas con Gemini Vision.
        
        Args:
            images: Lista de diccionarios con:
                - 'data' (bytes o str base64)
                - 'mime_type' (str)
        
        Returns:
            Hallazgos visuales como string
        """
        if not images:
            return "No se proporcionaron imÃ¡genes para anÃ¡lisis."
        
        # Preparar contenido del mensaje
        content = [{
            "type": "text",
            "text": f"""Analiza estas {len(images)} imÃ¡genes mÃ©dicas y proporciona una lista de HALLAZGOS CLAVES.

Formato de salida:
HALLAZGO 1: [DescripciÃ³n especÃ­fica del hallazgo]
HALLAZGO 2: [DescripciÃ³n especÃ­fica del hallazgo]
...

EnfÃ³cate en:
- AnomalÃ­as visibles
- CaracterÃ­sticas anatÃ³micas relevantes
- Patrones de interÃ©s clÃ­nico
- Comparaciones con normalidad esperada

SÃ© especÃ­fico y objetivo. Evita diagnÃ³sticos definitivos."""
        }]
        
        # Agregar imÃ¡genes
        for idx, img in enumerate(images):
            try:
                # Manejar tanto bytes como base64 string
                image_data_raw = img.get('data') or img.get('bytes')
                
                if isinstance(image_data_raw, bytes):
                    image_data_b64 = self.encode_image(image_data_raw)
                elif isinstance(image_data_raw, str):
                    image_data_b64 = image_data_raw
                else:
                    print(f"âš ï¸ Tipo de dato no soportado para imagen {idx}: {type(image_data_raw)}")
                    continue
                
                mime_type = self.get_mime_type(img.get('mime_type', 'image/png'))
                
                content.append({
                    "type": "image_url",
                    "image_url": f"data:{mime_type};base64,{image_data_b64}"
                })
                
                print(f"âœ… Imagen {idx} agregada: {mime_type}")
                
            except Exception as e:
                print(f"âŒ Error procesando imagen {idx}: {e}")
                continue
        
        message = HumanMessage(content=content)
        
        try:
            response = self.llm.invoke([message])
            print(f"âœ… AnÃ¡lisis de imÃ¡genes completado")
            return response.content
        except Exception as e:
            error_msg = f"Error en anÃ¡lisis de imÃ¡genes: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    async def classify_query(self, query: str, context: str, visual_findings: str) -> str:
        """Clasifica la consulta mÃ©dica."""
        system_prompt = """Eres un mÃ©dico especialista que analiza consultas mÃ©dicas.
Tu tarea es identificar:
1. El tipo de consulta (diagnÃ³stico, seguimiento, segunda opiniÃ³n, etc.)
2. Los hallazgos visuales mencionados o relevantes
3. Las palabras clave mÃ©dicas importantes

Formato de respuesta:
TIPO_CONSULTA: [tipo]
HALLAZGOS_RELEVANTES: [lista]
KEYWORDS_MEDICAS: [palabras clave]
ESPECIALIDAD_SUGERIDA: [especialidad mÃ©dica relevante]"""
        
        user_prompt = f"""
HALLAZGOS VISUALES IDENTIFICADOS:
{visual_findings}

CONTEXTO DE CONVERSACIÃ“N PREVIA:
{context}

CONSULTA DEL PACIENTE/USUARIO:
{query}

Clasifica esta consulta mÃ©dica segÃºn los hallazgos y el contexto proporcionado."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error en clasificaciÃ³n: {str(e)}"
    
    async def generate_search_queries(self, classification: str, visual_findings: str, 
                                     original_query: str) -> str:
        """Genera consultas de bÃºsqueda optimizadas."""
        system_prompt = """Eres un experto en bÃºsqueda de informaciÃ³n mÃ©dica.
Genera consultas de bÃºsqueda mÃ©dicas precisas y profesionales.

Reglas:
- Usa terminologÃ­a mÃ©dica precisa
- EnfÃ³cate en informaciÃ³n clÃ­nica relevante
- Prioriza fuentes mÃ©dicas confiables

Responde SOLO con la consulta de bÃºsqueda optimizada, sin explicaciones."""
        
        user_prompt = f"""
CLASIFICACIÃ“N MÃ‰DICA:
{classification}

HALLAZGOS VISUALES:
{visual_findings}

CONSULTA ORIGINAL:
{original_query}

Genera la mejor consulta de bÃºsqueda mÃ©dica para esta informaciÃ³n."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error generando consultas: {str(e)}"
    
    async def search_medical_info(self, search_query: str) -> str:
        """Busca informaciÃ³n mÃ©dica en Tavily."""
        try:
            result = self.tavily_tool.invoke({"query": search_query})
            
            if isinstance(result, list) and len(result) > 0:
                content = result[0].get('answer', result[0].get('content', ''))
                return f"BÃºsqueda: {search_query}\n{content}"
            else:
                return f"BÃºsqueda: {search_query}\nNo se encontrÃ³ informaciÃ³n especÃ­fica."
        except Exception as e:
            return f"Error en bÃºsqueda: {str(e)}"
    
    async def generate_medical_response(self, query: str, context: str, 
                                       classification: str, visual_findings: str,
                                       search_info: str) -> str:
        """Genera la respuesta mÃ©dica final."""
        system_prompt = """Eres un mÃ©dico especialista experimentado que proporciona anÃ¡lisis mÃ©dicos claros y profesionales.

**Estructura tu respuesta en estas secciones:**
1. DESCRIPCIÃ“N GENERAL: Resumen breve de la consulta
2. HALLAZGOS PRINCIPALES: Basado en los hallazgos visuales identificados
3. INTERPRETACIÃ“N CLÃNICA: Integra la informaciÃ³n de bÃºsqueda mÃ©dica
4. CONSIDERACIONES DIAGNÃ“STICAS: Posibles diagnÃ³sticos diferenciales
5. RECOMENDACIONES: Pasos siguientes sugeridos

**Reglas importantes:**
- Usa lenguaje mÃ©dico profesional pero accesible
- Siempre incluye disclaimers apropiados (no sustituye consulta mÃ©dica presencial)
- Basa tus conclusiones en evidencia
- SÃ© claro sobre las limitaciones del anÃ¡lisis remoto
- Nunca proporciones diagnÃ³sticos definitivos"""
        
        user_prompt = f"""
**CONSULTA ORIGINAL DEL USUARIO:**
{query}

**CONTEXTO DE CONVERSACIÃ“N ANTERIOR:**
{context}

**CLASIFICACIÃ“N MÃ‰DICA:**
{classification}

**HALLAZGOS VISUALES DE LAS IMÃGENES:**
{visual_findings}

**INFORMACIÃ“N MÃ‰DICA DE BÃšSQUEDA:**
{search_info}

Proporciona un anÃ¡lisis mÃ©dico completo y profesional."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            return f"Error generando respuesta: {str(e)}"
    
    async def stream(self, query: str, context_id: str, 
                    images: list[dict] = None) -> AsyncIterable[dict[str, Any]]:
        """
        Procesa una consulta mÃ©dica con streaming.
        
        IMPORTANTE: Este mÃ©todo DEBE yieldar diccionarios con estas claves:
        - 'is_task_complete': bool
        - 'require_user_input': bool
        - 'content': str
        - 'status': str (opcional)
        """
        print(f"\n{'='*80}")
        print(f"ğŸ¥ Procesando consulta mÃ©dica")
        print(f"Context ID: {context_id}")
        print(f"Query: {query[:100]}...")
        print(f"ImÃ¡genes recibidas: {len(images) if images else 0}")
        print(f"{'='*80}\n")
        
        # Obtener contexto de memoria
        memory_context = self._get_memory_context(context_id)
        
        # PASO 1: Analizar imÃ¡genes si existen
        visual_findings = ""
        if images and len(images) > 0:
            print(f"ğŸ“¸ Analizando {len(images)} imagen(es)...")
            
            yield {
                'is_task_complete': False,
                'require_user_input': False,
                'content': f'ğŸ” Analizando {len(images)} imagen(es) mÃ©dica(s)...',
                'status': 'analyzing_images'
            }
            
            visual_findings = await self.analyze_images(images)
            self.visual_findings[context_id] = visual_findings
            
            print(f"âœ… AnÃ¡lisis visual completado")
            
            yield {
                'is_task_complete': False,
                'require_user_input': False,
                'content': f'âœ… Hallazgos visuales identificados.',
                'status': 'analyzing_images'
            }
        else:
            visual_findings = self.visual_findings.get(
                context_id, 
                "No se proporcionaron imÃ¡genes para anÃ¡lisis."
            )
        
        # PASO 2: Clasificar consulta
        print(f"ğŸ” Clasificando consulta...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'ğŸ¥ Clasificando consulta mÃ©dica...',
            'status': 'classifying'
        }
        
        classification = await self.classify_query(query, memory_context, visual_findings)
        print(f"âœ… ClasificaciÃ³n completada")
        
        # PASO 3: Generar consultas de bÃºsqueda
        print(f"ğŸ” Generando consultas de bÃºsqueda...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'ğŸ” Buscando informaciÃ³n mÃ©dica relevante...',
            'status': 'searching'
        }
        
        search_query = await self.generate_search_queries(
            classification, visual_findings, query
        )
        
        # PASO 4: Buscar informaciÃ³n
        print(f"ğŸŒ Buscando informaciÃ³n mÃ©dica...")
        search_info = await self.search_medical_info(search_query)
        print(f"âœ… BÃºsqueda completada")
        
        # PASO 5: Generar respuesta final
        print(f"ğŸ“ Generando respuesta mÃ©dica final...")
        yield {
            'is_task_complete': False,
            'require_user_input': False,
            'content': 'ğŸ“ Generando anÃ¡lisis mÃ©dico completo...',
            'status': 'generating_response'
        }
        
        final_response = await self.generate_medical_response(
            query, memory_context, classification, visual_findings, search_info
        )
        
        print(f"âœ… Respuesta generada: {len(final_response)} caracteres")
        print(f"ğŸ“„ Respuesta preview: {final_response[:200]}...")
        
        # Guardar en memoria
        self._save_to_memory(context_id, query, final_response)
        
        print(f"âœ… Consulta mÃ©dica completada\n")
        
        # CRÃTICO: Retornar respuesta final con is_task_complete=True
        yield {
            'is_task_complete': True,
            'require_user_input': False,
            'content': final_response,
            'status': 'completed'
        }
